{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop_rate = 0.4\n",
    "# warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import gc\n",
    "import glob\n",
    "from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n",
    "import multiprocessing\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "\n",
    "from fastprogress import master_bar, progress_bar\n",
    "from keras.preprocessing import text, sequence\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize.treebank import TreebankWordTokenizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import shap\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tqdm._tqdm_notebook import tqdm_notebook as tqdm\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.utils.data import Dataset, DataLoader, Subset, TensorDataset\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set(style='ticks')\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/ildoonet/pytorch-gradual-warmup-lr/blob/master/warmup_scheduler/scheduler.py\n",
    "\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "\n",
    "class GradualWarmupScheduler(_LRScheduler):\n",
    "    \"\"\" Gradually warm-up(increasing) learning rate in optimizer.\n",
    "    Proposed in 'Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour'.\n",
    "    Args:\n",
    "        optimizer (Optimizer): Wrapped optimizer.\n",
    "        multiplier: target learning rate = base lr * multiplier\n",
    "        total_epoch: target learning rate is reached at total_epoch, gradually\n",
    "        after_scheduler: after target_epoch, use this scheduler(eg. ReduceLROnPlateau)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, optimizer, multiplier, total_epoch, after_scheduler=None):\n",
    "        self.multiplier = multiplier\n",
    "        if self.multiplier <= 1.:\n",
    "            raise ValueError('multiplier should be greater than 1.')\n",
    "        self.total_epoch = total_epoch\n",
    "        self.after_scheduler = after_scheduler\n",
    "        self.finished = False\n",
    "        super().__init__(optimizer)\n",
    "\n",
    "    def get_lr(self):\n",
    "        if self.last_epoch > self.total_epoch:\n",
    "            if self.after_scheduler:\n",
    "                if not self.finished:\n",
    "                    self.after_scheduler.base_lrs = [base_lr * self.multiplier for base_lr in self.base_lrs]\n",
    "                    self.finished = True\n",
    "                return self.after_scheduler.get_lr()\n",
    "            return [base_lr * self.multiplier for base_lr in self.base_lrs]\n",
    "\n",
    "        return [base_lr * ((self.multiplier - 1.) * self.last_epoch / self.total_epoch + 1.) for base_lr in self.base_lrs]\n",
    "\n",
    "    def step_ReduceLROnPlateau(self, metrics, epoch=None):\n",
    "        if epoch is None:\n",
    "            epoch = self.last_epoch + 1\n",
    "        self.last_epoch = epoch if epoch != 0 else 1  # ReduceLROnPlateau is called at the end of epoch, whereas others are called at beginning\n",
    "        if self.last_epoch <= self.total_epoch:\n",
    "            warmup_lr = [base_lr * ((self.multiplier - 1.) * self.last_epoch / self.total_epoch + 1.) for base_lr in self.base_lrs]\n",
    "            for param_group, lr in zip(self.optimizer.param_groups, warmup_lr):\n",
    "                param_group['lr'] = lr\n",
    "        else:\n",
    "            if epoch is None:\n",
    "                self.after_scheduler.step(metrics, None)\n",
    "            else:\n",
    "                self.after_scheduler.step(metrics, epoch - self.total_epoch)\n",
    "\n",
    "    def step(self, epoch=None, metrics=None):\n",
    "        if type(self.after_scheduler) != ReduceLROnPlateau:\n",
    "            if self.finished and self.after_scheduler:\n",
    "                if epoch is None:\n",
    "                    self.after_scheduler.step(None)\n",
    "                else:\n",
    "                    self.after_scheduler.step(epoch - self.total_epoch)\n",
    "            else:\n",
    "                return super(GradualWarmupScheduler, self).step(epoch)\n",
    "        else:\n",
    "            self.step_ReduceLROnPlateau(metrics, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "def get_logger():\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    # handler1\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(asctime)s %(levelname)8s %(message)s\"))\n",
    "    # handler2\n",
    "    handler2 = FileHandler(filename=datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")+\".log\")\n",
    "    handler2.setFormatter(Formatter(\"%(asctime)s %(levelname)8s %(message)s\"))\n",
    "    # addHandler\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "def seed_everything(seed=123):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def log_loss(y_true, y_pred, epsilon=1e-12):\n",
    "    y_pred = np.clip(y_pred, epsilon, 1-epsilon)\n",
    "    return -(np.log(y_pred) * y_true + np.log(1 - y_pred) * (1 - y_true))\n",
    "\n",
    "class JigsawEvaluator:\n",
    "    def __init__(self, y_true, y_identity, power=-5, overall_model_weight=0.25):\n",
    "        self.y = (y_true >= 0.5).astype(int)\n",
    "        self.y_i = (y_identity >= 0.5).astype(int)\n",
    "        self.n_subgroups = self.y_i.shape[1]\n",
    "        self.power = power\n",
    "        self.overall_model_weight = overall_model_weight\n",
    "\n",
    "    @staticmethod\n",
    "    def _compute_auc(y_true, y_pred):\n",
    "        try:\n",
    "            return roc_auc_score(y_true, y_pred)\n",
    "        except ValueError:\n",
    "            return np.nan\n",
    "\n",
    "    def _compute_subgroup_auc(self, i, y_pred):\n",
    "        mask = self.y_i[:, i] == 1\n",
    "        return self._compute_auc(self.y[mask], y_pred[mask])\n",
    "\n",
    "    def _compute_bpsn_auc(self, i, y_pred):\n",
    "        mask = self.y_i[:, i] + self.y == 1\n",
    "        return self._compute_auc(self.y[mask], y_pred[mask])\n",
    "\n",
    "    def _compute_bnsp_auc(self, i, y_pred):\n",
    "        mask = self.y_i[:, i] + self.y != 1\n",
    "        return self._compute_auc(self.y[mask], y_pred[mask])\n",
    "\n",
    "    def compute_bias_metrics_for_model(self, y_pred):\n",
    "        records = np.zeros((3, self.n_subgroups))\n",
    "        for i in range(self.n_subgroups):\n",
    "            records[0, i] = self._compute_subgroup_auc(i, y_pred)\n",
    "            records[1, i] = self._compute_bpsn_auc(i, y_pred)\n",
    "            records[2, i] = self._compute_bnsp_auc(i, y_pred)\n",
    "        return records\n",
    "\n",
    "    def _calculate_overall_auc(self, y_pred):\n",
    "        return roc_auc_score(self.y, y_pred)\n",
    "\n",
    "    def _power_mean(self, array):\n",
    "        total = sum(np.power(array, self.power))\n",
    "        return np.power(total / len(array), 1 / self.power)\n",
    "\n",
    "    def get_final_metric(self, y_pred):\n",
    "        bias_metrics = self.compute_bias_metrics_for_model(y_pred)\n",
    "        bias_score = np.average([\n",
    "            self._power_mean(bias_metrics[0]),\n",
    "            self._power_mean(bias_metrics[1]),\n",
    "            self._power_mean(bias_metrics[2])\n",
    "        ])\n",
    "        overall_score = self.overall_model_weight * self._calculate_overall_auc(y_pred)\n",
    "        bias_score = (1 - self.overall_model_weight) * bias_score\n",
    "        return overall_score + bias_score, bias_metrics[0], bias_metrics[1], bias_metrics[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logger\n",
    "logger = get_logger()\n",
    "\n",
    "# parameters\n",
    "n_workers = 4\n",
    "n_splits = 5\n",
    "seed = 777\n",
    "seed_everything(seed)\n",
    "\n",
    "maxlen = 300\n",
    "max_features = 410047\n",
    "\n",
    "batch_size = 512\n",
    "lr = 0.001\n",
    "epochs = 10\n",
    "n_fold = 1\n",
    "drop_rate = 0.4 # default=0.3\n",
    "\n",
    "# path\n",
    "CRAWL_EMBEDDING_PATH = '../input/pickled-crawl300d2m-for-kernel-competitions/crawl-300d-2M.pkl'\n",
    "GLOVE_EMBEDDING_PATH = '../input/pickled-glove840b300d-for-10sec-loading/glove.840B.300d.pkl'\n",
    "# GOOGLE_EMBEDDING_PATH = '../input/quoratextemb/embeddings/GoogleNews-vectors-negative300/GoogleNews-vectors-negative300.bin'\n",
    "# WIKI_EMBEDDING_PATH = '../input/quoratextemb/embeddings/wiki-news-300d-1M/wiki-news-300d-1M.vec'\n",
    "\n",
    "# constants\n",
    "target = 'target'\n",
    "aux_target = ['severe_toxicity', 'obscene', 'identity_attack', 'insult', 'threat']\n",
    "identity_columns = [\n",
    "    'male', 'female', 'homosexual_gay_or_lesbian', 'christian', 'jewish',\n",
    "    'muslim', 'black', 'white', 'psychiatric_or_mental_illness'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (1804874, 45)\n",
      "test shape: (97320, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>severe_toxicity</th>\n",
       "      <th>obscene</th>\n",
       "      <th>identity_attack</th>\n",
       "      <th>insult</th>\n",
       "      <th>threat</th>\n",
       "      <th>asian</th>\n",
       "      <th>atheist</th>\n",
       "      <th>bisexual</th>\n",
       "      <th>black</th>\n",
       "      <th>buddhist</th>\n",
       "      <th>christian</th>\n",
       "      <th>female</th>\n",
       "      <th>heterosexual</th>\n",
       "      <th>hindu</th>\n",
       "      <th>homosexual_gay_or_lesbian</th>\n",
       "      <th>intellectual_or_learning_disability</th>\n",
       "      <th>jewish</th>\n",
       "      <th>latino</th>\n",
       "      <th>male</th>\n",
       "      <th>muslim</th>\n",
       "      <th>other_disability</th>\n",
       "      <th>other_gender</th>\n",
       "      <th>other_race_or_ethnicity</th>\n",
       "      <th>other_religion</th>\n",
       "      <th>other_sexual_orientation</th>\n",
       "      <th>physical_disability</th>\n",
       "      <th>psychiatric_or_mental_illness</th>\n",
       "      <th>transgender</th>\n",
       "      <th>white</th>\n",
       "      <th>created_date</th>\n",
       "      <th>publication_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>funny</th>\n",
       "      <th>wow</th>\n",
       "      <th>sad</th>\n",
       "      <th>likes</th>\n",
       "      <th>disagree</th>\n",
       "      <th>sexual_explicit</th>\n",
       "      <th>identity_annotator_count</th>\n",
       "      <th>toxicity_annotator_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59848</td>\n",
       "      <td>0.0</td>\n",
       "      <td>This is so cool. It's like, 'would you want yo...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-09-29 10:50:41.987077+00</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2006</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59849</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Thank you!! This would make my life a lot less...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-09-29 10:50:42.870083+00</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2006</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59852</td>\n",
       "      <td>0.0</td>\n",
       "      <td>This is such an urgent design problem; kudos t...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-09-29 10:50:45.222647+00</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2006</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id            ...             toxicity_annotator_count\n",
       "0  59848            ...                                    4\n",
       "1  59849            ...                                    4\n",
       "2  59852            ...                                    4\n",
       "\n",
       "[3 rows x 45 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('../input/jigsaw-unintended-bias-in-toxicity-classification/train.csv')\n",
    "test = pd.read_csv('../input/jigsaw-unintended-bias-in-toxicity-classification/test.csv')\n",
    "print(f'train shape: {train.shape}')\n",
    "print(f'test shape: {test.shape}')\n",
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7000000</td>\n",
       "      <td>Jeff Sessions is another one of Trump's Orwell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7000001</td>\n",
       "      <td>I actually inspected the infrastructure on Gra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7000002</td>\n",
       "      <td>No it won't . That's just wishful thinking on ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                       comment_text\n",
       "0  7000000  Jeff Sessions is another one of Trump's Orwell...\n",
       "1  7000001  I actually inspected the infrastructure on Gra...\n",
       "2  7000002  No it won't . That's just wishful thinking on ..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "y shape: (1804874, 8)\n"
     ]
    }
   ],
   "source": [
    "# Overall\n",
    "weights = np.ones((len(train),)) / 4\n",
    "\n",
    "# Subgroup\n",
    "weights += (train[identity_columns].fillna(0).values>=0.5).sum(axis=1).astype(bool).astype(np.int) / 4\n",
    "\n",
    "# Background Positive, Subgroup Negative\n",
    "weights += (((train[target].values>=0.5).astype(bool).astype(np.int) +\n",
    "   (1-(train[identity_columns].fillna(0).values>=0.5).sum(axis=1).astype(bool).astype(np.int)) ) > 1).astype(bool).astype(np.int) / 4\n",
    "\n",
    "# Background Negative, Subgroup Positive\n",
    "weights += (((train[target].values<0.5).astype(bool).astype(np.int) +\n",
    "   (train[identity_columns].fillna(0).values>=0.5).sum(axis=1).astype(bool).astype(np.int) ) > 1).astype(bool).astype(np.int) / 4\n",
    "\n",
    "#loss_weight = 1.0 / weights.mean()\n",
    "loss_weight = 0.5\n",
    "print(loss_weight)\n",
    "\n",
    "y_train = np.vstack([train[target], weights]).T\n",
    "# y_train = np.vstack([np.where(train[target]>=0.5, train[target], 0), weights]).T\n",
    "y_aux_train = train[[target]+aux_target]\n",
    "y_train = np.hstack([y_train, y_aux_train])\n",
    "print(f'y shape: {y_train.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_pickle('../input/toxicpreprocesseddata/X_train.pkl')\n",
    "X_test = pd.read_pickle('../input/toxicpreprocesseddata/X_test.pkl')\n",
    "embedding_matrix = pd.read_pickle('../input/toxicpreprocesseddata/embedding_matrix.pkl')\n",
    "tokenizer = pd.read_pickle('../input/toxicpreprocesseddata/tokenizer.pkl')\n",
    "train_lengths = pd.read_pickle('../input/toxicpreprocesseddata/train_lengths.pkl')\n",
    "test_lengths = pd.read_pickle('../input/toxicpreprocesseddata/test_lengths.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceBucketCollator():\n",
    "    def __init__(self, choose_length, sequence_index, length_index, label_index=None):\n",
    "        self.choose_length = choose_length\n",
    "        self.sequence_index = sequence_index\n",
    "        self.length_index = length_index\n",
    "        self.label_index = label_index\n",
    "        \n",
    "    def __call__(self, batch):\n",
    "        batch = [torch.stack(x) for x in list(zip(*batch))]\n",
    "        \n",
    "        sequences = batch[self.sequence_index]\n",
    "        lengths = batch[self.length_index]\n",
    "        \n",
    "        length = self.choose_length(lengths)\n",
    "        mask = torch.arange(start=maxlen, end=0, step=-1) < length\n",
    "        padded_sequences = sequences[:, mask]\n",
    "        \n",
    "        batch[self.sequence_index] = padded_sequences\n",
    "        \n",
    "        if self.label_index is not None:\n",
    "            return [x for i, x in enumerate(batch) if i != self.label_index], batch[self.label_index]\n",
    "    \n",
    "        return batch\n",
    "    \n",
    "def prepare_data_loader(X, lengths, y=None, shuffle=False):\n",
    "    if y is None:\n",
    "        dataset = TensorDataset(torch.from_numpy(X), \n",
    "                                torch.from_numpy(lengths))\n",
    "        collator = SequenceBucketCollator(lambda lenghts: lenghts.max(), \n",
    "                                          sequence_index=0, \n",
    "                                          length_index=1)\n",
    "    else:\n",
    "        dataset = TensorDataset(torch.from_numpy(X), \n",
    "                                torch.from_numpy(lengths), \n",
    "                                torch.tensor(y, dtype=torch.float32))\n",
    "        collator = SequenceBucketCollator(lambda lenghts: lenghts.max(), \n",
    "                                          sequence_index=0, \n",
    "                                          length_index=1, \n",
    "                                          label_index=2)\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, collate_fn=collator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(data, targets):\n",
    "    ''' Define custom loss function for weighted BCE on 'target' column '''\n",
    "    bce_loss_1 = nn.BCEWithLogitsLoss(weight=targets[:, 1:2])(data[:, :1], targets[:, :1])\n",
    "    bce_loss_2 = nn.BCEWithLogitsLoss()(data[:, 1:], targets[:, 2:])\n",
    "    return (bce_loss_1 * loss_weight) + bce_loss_2\n",
    "\n",
    "#def custom_loss(data, targets):\n",
    "#    ''' Define custom loss function for weighted BCE on 'target' column '''\n",
    "#    bce_loss_1 = nn.BCEWithLogitsLoss(weight=targets[:, 1:2])(data[:, :1], targets[:, :1])\n",
    "#    return bce_loss_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpatialDropout(nn.Dropout2d):\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(2)    # (N, T, 1, K)\n",
    "        x = x.permute(0, 3, 2, 1)  # (N, K, 1, T)\n",
    "        x = super(SpatialDropout, self).forward(x)  # (N, K, 1, T), some features are masked\n",
    "        x = x.permute(0, 3, 2, 1)  # (N, T, 1, K)\n",
    "        x = x.squeeze(2)  # (N, T, K)\n",
    "        return x\n",
    "    \n",
    "class EmbLSTM(nn.Module):\n",
    "    def __init__(self, embedding_matrix, max_features, num_aux_targets=6):\n",
    "        super().__init__()\n",
    "        embed_size = embedding_matrix.shape[1]\n",
    "        \n",
    "        self.embedding = nn.Embedding(max_features, embed_size)\n",
    "        self.embedding.weight = nn.Parameter(torch.tensor(embedding_matrix, dtype=torch.float32))\n",
    "        self.embedding.weight.requires_grad = False\n",
    "        self.embedding_dropout = SpatialDropout(drop_rate)\n",
    "        \n",
    "        self.lstm1 = nn.LSTM(embed_size, 128, bidirectional=True, batch_first=True)\n",
    "        self.lstm2 = nn.LSTM(128 * 2, 128, bidirectional=True, batch_first=True)\n",
    "        #self.lstm2 = nn.GRU(128 * 2, 128, bidirectional=True, batch_first=True)\n",
    "    \n",
    "        self.linear1 = nn.Linear(512, 512)\n",
    "        self.linear2 = nn.Linear(512, 512)\n",
    "        #self.linear1 = nn.Sequential(\n",
    "        #    nn.BatchNorm1d(512),\n",
    "        #    nn.Linear(512, 512),\n",
    "        #    #nn.PReLU(),\n",
    "        #    nn.ReLU(inplace=True),\n",
    "        #)\n",
    "        #self.linear2 = nn.Sequential(\n",
    "        #    nn.BatchNorm1d(512),\n",
    "        #    nn.Linear(512, 512),\n",
    "        #    #nn.PReLU(),\n",
    "        #    nn.ReLU(inplace=True),\n",
    "        #)\n",
    "        \n",
    "        self.linear_out = nn.Linear(512, 1)\n",
    "        self.linear_aux_out = nn.Linear(512, num_aux_targets)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h_embedding = self.embedding(x)\n",
    "        h_embedding = self.embedding_dropout(h_embedding)\n",
    "        \n",
    "        h_lstm1, _ = self.lstm1(h_embedding)\n",
    "        h_lstm2, _ = self.lstm2(h_lstm1)\n",
    "        \n",
    "        # global average pooling\n",
    "        avg_pool = torch.mean(h_lstm2, 1)\n",
    "        # global max pooling\n",
    "        max_pool, _ = torch.max(h_lstm2, 1)\n",
    "        \n",
    "        h_conc = torch.cat((max_pool, avg_pool), 1)\n",
    "        h_conc_linear1  = F.relu(self.linear1(h_conc))\n",
    "        h_conc_linear2  = F.relu(self.linear2(h_conc))\n",
    "        \n",
    "        hidden = h_conc + h_conc_linear1 + h_conc_linear2\n",
    "        \n",
    "        result = self.linear_out(hidden)\n",
    "        aux_result = self.linear_aux_out(hidden)\n",
    "        \n",
    "        out = torch.cat([result, aux_result], 1)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "class EmbLSTMGRUCNN(nn.Module):\n",
    "    def __init__(self, embedding_matrix, max_features, num_aux_targets=6):\n",
    "        super().__init__()\n",
    "        embed_size = embedding_matrix.shape[1]\n",
    "        \n",
    "        self.embedding = nn.Embedding(max_features, embed_size)\n",
    "        self.embedding.weight = nn.Parameter(torch.tensor(embedding_matrix, dtype=torch.float32))\n",
    "        self.embedding.weight.requires_grad = False\n",
    "        self.embedding_dropout = SpatialDropout(drop_rate)\n",
    "        \n",
    "        self.lstm1 = nn.LSTM(embed_size, 80, bidirectional=True, batch_first=True)\n",
    "        self.lstm2 = nn.GRU(80*2, 80, bidirectional=True, batch_first=True)\n",
    "        self.cnn = nn.Conv1d(80*2, 64, kernel_size=3, padding=0)\n",
    "    \n",
    "        self.linear1 = nn.Sequential(\n",
    "            nn.BatchNorm1d(458),\n",
    "            nn.Linear(458, 458),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.linear2 = nn.Sequential(\n",
    "            nn.BatchNorm1d(458),\n",
    "            nn.Linear(458, 458),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.linear_out = nn.Linear(458, 1)\n",
    "        self.linear_aux_out = nn.Linear(458, num_aux_targets)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h_embedding = self.embedding(x)\n",
    "        h_embedding = self.embedding_dropout(h_embedding)\n",
    "        \n",
    "        h_lstm1, _ = self.lstm1(h_embedding)\n",
    "        h_lstm2, _ = self.lstm2(h_lstm1)\n",
    "        x = self.cnn(h_lstm2.permute(0, 2, 1))\n",
    "        \n",
    "        # global average pooling\n",
    "        avg_pool = torch.mean(x, 1)\n",
    "        # global max pooling\n",
    "        max_pool, _ = torch.max(x, 1)\n",
    "        \n",
    "        h_conc = torch.cat((max_pool, avg_pool), 1)\n",
    "        h_conc_linear1  = self.linear1(h_conc)\n",
    "        h_conc_linear2  = self.linear2(h_conc)\n",
    "        \n",
    "        hidden = h_conc + h_conc_linear1 + h_conc_linear2\n",
    "        \n",
    "        result = self.linear_out(hidden)\n",
    "        aux_result = self.linear_aux_out(hidden)\n",
    "        out = torch.cat([result, aux_result], 1)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(filepath, model, optimizer, epoch):\n",
    "    state = {\n",
    "        'epoch': epoch,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "    }\n",
    "    torch.save(state, filepath)\n",
    "\n",
    "def plot_losses(train_losses, valid_losses, fold=0):\n",
    "    plt.clf()\n",
    "    plt.plot(train_losses, label='train')\n",
    "    plt.plot(valid_losses, label='valid')\n",
    "    plt.legend()\n",
    "    plt.title(f'loss history of fold {fold}')\n",
    "    plt.savefig(f'loss_history_of_fold_{fold}.png')\n",
    "    plt.show()\n",
    "    \n",
    "def plot_histogram(y_true, y_pred, n_bins=50, fold=0):\n",
    "    bins = np.linspace(0, 1, n_bins)\n",
    "    plt.clf()\n",
    "    plt.hist(y_pred[:, 0], bins=bins, label='pred')\n",
    "    plt.hist(y_true[:, 0], bins=bins, label='true')\n",
    "    plt.legend()\n",
    "    plt.title(f'validation histogram of fold {fold}')\n",
    "    plt.savefig(f'validation_histogram_of_fold_{fold}.png')\n",
    "    plt.show()\n",
    "    \n",
    "def plot_aucs(aucs, auc_type, fold=0):\n",
    "    total = sum(np.power(aucs, -5))\n",
    "    score = np.power(total / len(aucs), 1 / -5)\n",
    "    \n",
    "    plt.clf()\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    ax = sns.barplot(identity_columns, aucs)\n",
    "    for p in ax.patches:\n",
    "        ax.annotate(f'{p.get_height():.4f}', (p.get_x()+p.get_width()/2, int(p.get_height()*0.95)),\n",
    "                    ha='center', va='center', fontsize=20, color='blue', xytext=(0, 20), \n",
    "                    textcoords='offset points')\n",
    "    plt.xticks(rotation=10)\n",
    "    plt.title(f'{auc_type} {score} barplot of fold {fold}')\n",
    "    plt.savefig(f'{auc_type}_{score}_barplot_of_fold_{fold}.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, X):\n",
    "    logits = model(X)\n",
    "    probabilities = torch.sigmoid(logits)\n",
    "    return logits, probabilities\n",
    "        \n",
    "def evaluate_single_epoch(model, dataloader, criterion, epoch, evaluator, return_pred=False):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        valid_preds = []\n",
    "        loss_list = []\n",
    "        for i, (X, y) in enumerate(dataloader):\n",
    "            X = X[0].cuda().long() # X[0]: text sequences, X[1]: lengths\n",
    "            y = y.cuda().float()\n",
    "            logits, probabilities = inference(model, X)\n",
    "            \n",
    "            loss = criterion(logits, y)\n",
    "            loss_list.append(loss.item())\n",
    "            valid_preds.append(probabilities.cpu().numpy())\n",
    "        valid_preds = np.concatenate(valid_preds)\n",
    "\n",
    "        log_dict = {}\n",
    "        score, subgroup_auc, bpsn_auc, bnsp_auc = evaluator.get_final_metric(valid_preds[:, 0])\n",
    "        log_dict['score'] = score\n",
    "        log_dict['subgroup_auc'] = subgroup_auc\n",
    "        log_dict['bpsn_auc'] = bpsn_auc\n",
    "        log_dict['bnsp_auc'] = bnsp_auc\n",
    "        log_dict['loss'] = np.mean(loss_list)\n",
    "        \n",
    "        if return_pred:\n",
    "            log_dict['pred'] = valid_preds\n",
    "            \n",
    "    return log_dict\n",
    "\n",
    "def train_single_epoch(model, dataloader, criterion, optimizer, epoch, parent_bar, scheduler=None):\n",
    "    model.train()\n",
    "    log_dict = {}\n",
    "    log_dict['loss'] = 0\n",
    "    for X, y in progress_bar(dataloader, parent=parent_bar):\n",
    "        X = X[0].cuda().long() # X[0]: text sequences, X[1]: lengths\n",
    "        y = y.cuda().float()\n",
    "        logits, probabilities = inference(model, X)\n",
    "        \n",
    "        loss = criterion(logits, y)\n",
    "        log_dict['loss'] += loss.item() / len(dataloader)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        log_dict['lr'] = optimizer.param_groups[0]['lr']\n",
    "        \n",
    "    if scheduler is not None:\n",
    "        scheduler.step()\n",
    "        \n",
    "    return log_dict\n",
    "\n",
    "def predict_model(model, dataloader):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_preds = []\n",
    "        for i, X in enumerate(dataloader):\n",
    "            X = X[0].cuda().long() # X[0]: text sequences, X[1]: lengths\n",
    "            logits, probabilities = inference(model, X)\n",
    "            test_preds.append(probabilities.cpu().numpy())\n",
    "    test_preds = np.concatenate(test_preds)\n",
    "    return test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kfold = train.copy()\n",
    "kfold['fold_id'] = 0\n",
    "\n",
    "cv = StratifiedKFold(n_splits=n_splits, random_state=seed, shuffle=True)\n",
    "for fold, (train_index, valid_index) in enumerate(cv.split(range(len(train)), np.where(train[target]>0.5, 1, 0))):\n",
    "    kfold.loc[valid_index, 'fold_id'] = fold\n",
    "kfold[['fold_id']].to_csv('fold01.csv', index=False)\n",
    "\n",
    "del kfold; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:33: RuntimeWarning: invalid value encountered in greater_equal\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1' class='' max='10', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      10.00% [1/10 08:42<1:18:19]\n",
       "    </div>\n",
       "    \n",
       "Epoch 1 - avg_train_loss: 0.1515  avg_val_loss: 0.1452  val_score: 0.929234<p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='614' class='' max='2821', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      21.77% [614/2821 01:42<06:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-16 15:18:05,834     INFO Epoch 1 - optimizer: [{'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False, 'initial_lr': 0.001, 'params': [140602648655120, 140602648655048, 140602648655192, 140602648655264, 140602648655336, 140602648655408, 140602648655480, 140602648655552, 140602648655624, 140602648655984, 140602648656056, 140602648656128, 140602648656200, 140602648656272, 140602648656344, 140602648656416, 140602648656488, 140602648656848, 140602648656920, 140602648656992, 140602648657064, 140602648657136, 140602648657208, 140602648657280, 140602648657352]}] - scheduler: {'multiplier': 1.2, 'total_epoch': 2, 'after_scheduler': <torch.optim.lr_scheduler.CosineAnnealingLR object at 0x7fe09aef5630>, 'finished': False, 'base_lrs': [0.001], 'last_epoch': 0}\n",
      "2019-06-16 15:26:44,344     INFO Epoch 1 - avg_train_loss: 0.1515 avg_val_loss: 0.1452  val_score: 0.929234\n",
      "2019-06-16 15:26:48,032     INFO Epoch 2 - optimizer: [{'lr': 0.0011, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False, 'initial_lr': 0.001, 'params': [140602648655120, 140602648655048, 140602648655192, 140602648655264, 140602648655336, 140602648655408, 140602648655480, 140602648655552, 140602648655624, 140602648655984, 140602648656056, 140602648656128, 140602648656200, 140602648656272, 140602648656344, 140602648656416, 140602648656488, 140602648656848, 140602648656920, 140602648656992, 140602648657064, 140602648657136, 140602648657208, 140602648657280, 140602648657352]}] - scheduler: {'multiplier': 1.2, 'total_epoch': 2, 'after_scheduler': <torch.optim.lr_scheduler.CosineAnnealingLR object at 0x7fe09aef5630>, 'finished': False, 'base_lrs': [0.001], 'last_epoch': 1}\n"
     ]
    }
   ],
   "source": [
    "#cv = StratifiedKFold(n_splits=n_splits, random_state=seed)\n",
    "for fold, (train_index, valid_index) in enumerate(cv.split(range(len(train)), np.where(train[target]>0.5, 1, 0))):\n",
    "    if fold==n_fold:\n",
    "        \n",
    "        # data split\n",
    "        X_trn, X_val = X_train[train_index], X_train[valid_index]\n",
    "        y_trn, y_val = y_train[train_index], y_train[valid_index]\n",
    "        trn_lengths, val_lengths = train_lengths[train_index], train_lengths[valid_index]\n",
    "        y_val_target = train.loc[valid_index, target].values\n",
    "        y_val_identity = train.loc[valid_index, identity_columns].values\n",
    "    \n",
    "        train_loader = prepare_data_loader(X_trn, trn_lengths, y=y_trn, shuffle=True)\n",
    "        valid_loader = prepare_data_loader(X_val, val_lengths, y=y_val, shuffle=False)\n",
    "        evaluator = JigsawEvaluator(y_val_target, y_val_identity)\n",
    "    \n",
    "        # model\n",
    "        model = EmbLSTM(embedding_matrix, max_features).cuda()\n",
    "        #model = EmbLSTMGRUCNN(embedding_matrix, max_features).cuda()\n",
    "        criterion = custom_loss\n",
    "        optimizer = torch.optim.Adam(params=model.parameters(), lr=lr, amsgrad=False)\n",
    "        scheduler_cosine = CosineAnnealingLR(optimizer, T_max=4, eta_min=1e-3)\n",
    "        scheduler = GradualWarmupScheduler(optimizer, multiplier=1.2, total_epoch=2, after_scheduler=scheduler_cosine)\n",
    "    #     scheduler = CosineAnnealingLR(optimizer, T_max=t_max, eta_min=eta_min)\n",
    "    #     scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lambda epoch: 0.6 ** epoch)\n",
    "    \n",
    "        # main loop\n",
    "        best_epoch = -1\n",
    "        best_score = 0.\n",
    "\n",
    "        train_losses, valid_losses = [], []\n",
    "\n",
    "        mb = master_bar(range(epochs))\n",
    "        for epoch in mb:\n",
    "            scheduler.step() # 2 epoch warmup, after that schedule as scheduler_cosine\n",
    "            logger.info(f'Epoch {epoch+1} - optimizer: {optimizer.state_dict()[\"param_groups\"]} - scheduler: {scheduler.state_dict()}')\n",
    "            log_dict_train = train_single_epoch(model, train_loader, criterion, optimizer, epoch, mb) # loss, lr\n",
    "            log_dict_valid = evaluate_single_epoch(model, valid_loader, criterion, epoch, evaluator) # loss, score\n",
    "            train_losses.append(log_dict_train['loss'])\n",
    "            valid_losses.append(log_dict_valid['loss'])\n",
    "\n",
    "            if (epoch + 1) % 1 == 0:\n",
    "                mb.write(f'Epoch {epoch+1} - avg_train_loss: {log_dict_train[\"loss\"]:.4f}  avg_val_loss: {log_dict_valid[\"loss\"]:.4f}  val_score: {log_dict_valid[\"score\"]:.6f}')\n",
    "                logger.info(f'Epoch {epoch+1} - avg_train_loss: {log_dict_train[\"loss\"]:.4f} avg_val_loss: {log_dict_valid[\"loss\"]:.4f}  val_score: {log_dict_valid[\"score\"]:.6f}')\n",
    "\n",
    "            if log_dict_valid[\"score\"] > best_score:\n",
    "                best_epoch = epoch + 1\n",
    "                best_score = log_dict_valid[\"score\"]\n",
    "                save_checkpoint(f'weight_best_fold_{fold}.pth', model, optimizer, epoch)\n",
    "                if epoch - best_epoch > 3:\n",
    "                    break\n",
    "\n",
    "        # load best\n",
    "        state = torch.load(f'weight_best_fold_{fold}.pth')\n",
    "        model.load_state_dict(state['state_dict'])\n",
    "        optimizer.load_state_dict(state['optimizer'])\n",
    "\n",
    "        # save valid\n",
    "        log_dict = evaluate_single_epoch(model, valid_loader, criterion, 0, evaluator, return_pred=True)\n",
    "        pred_valid = log_dict['pred']\n",
    "        np.save(f'pred_valid_fold_{fold}.npy', pred_valid)\n",
    "\n",
    "        # evaluate\n",
    "        score, subgroup_auc, bpsn_auc, bnsp_auc = evaluator.get_final_metric(pred_valid[:, 0])\n",
    "        subgroup_auc = evaluator._power_mean(subgroup_auc)\n",
    "        bpsn_auc = evaluator._power_mean(bpsn_auc)\n",
    "        bnsp_auc = evaluator._power_mean(bnsp_auc)\n",
    "        overall_auc = evaluator._calculate_overall_auc(pred_valid[:, 0])\n",
    "        logger.info(f'metric: {score:.6f}, overall auc: {overall_auc:.6f}, subgroup_auc: {subgroup_auc:.6f}, bpsn_auc: {bpsn_auc:.6f}, bnsp_auc: {bnsp_auc:.6f}')\n",
    "        \n",
    "        # plot\n",
    "        plot_losses(train_losses, valid_losses, fold=fold)\n",
    "        plot_histogram(y_val, pred_valid, n_bins=50, fold=fold)\n",
    "        plot_aucs(log_dict['subgroup_auc'], 'subgroup_auc', fold=fold)\n",
    "        plot_aucs(log_dict['bpsn_auc'], 'bpsn_auc', fold=fold)\n",
    "        plot_aucs(log_dict['bnsp_auc'], 'bnsp_auc', fold=fold)\n",
    "    \n",
    "        del model; gc.collect(); torch.cuda.empty_cache()\n",
    "    \n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>target</th>\n",
       "      <th>pred</th>\n",
       "      <th>logloss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1774794</th>\n",
       "      <td>6296556</td>\n",
       "      <td>This will never stop unless you go after family and friends that knew. And that means do not take their word for it stupiid</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.007588</td>\n",
       "      <td>4.881168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1571265</th>\n",
       "      <td>6044462</td>\n",
       "      <td>Nigga Please</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.004163</td>\n",
       "      <td>4.686455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1552125</th>\n",
       "      <td>6021195</td>\n",
       "      <td>your post is stupid\\nplease reread</td>\n",
       "      <td>0.897959</td>\n",
       "      <td>0.011885</td>\n",
       "      <td>3.981387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107748</th>\n",
       "      <td>373929</td>\n",
       "      <td>Alaska wilderness - 1\\nIdiot - 0</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.012905</td>\n",
       "      <td>3.808011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687700</th>\n",
       "      <td>1082705</td>\n",
       "      <td>Why I said what I said. My imbécil is tightening as we speak.</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.009328</td>\n",
       "      <td>3.741680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1179407</th>\n",
       "      <td>5557347</td>\n",
       "      <td>one ILH in top tier? Shows oia is scaid  ILH would play against itself every year.</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.009414</td>\n",
       "      <td>3.734343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496912</th>\n",
       "      <td>5952533</td>\n",
       "      <td>Hey Mike, You, like AK Snowman above, are in the dark. Sure glaciers are generally in retreat around the planet but the retreat began around 1800 at the end of the Little Ice Age. Go to the Glacier Bay National Park Website and open the official GBNP brochure. On it, is a map of GB demarcating the retreat of the Grand Pacific (GP) Glacier since 1794 when Geoge Vancouver first \"discovered\" Glacier Bay (at that time a 5 mile indentation in the shoreline). In 1794 the Bay was walled off by the enormous 4000' thick and 20 mile wide GP Glacier! From 1794 to 1912 the GP Glacier retreated over 80 Miles! Since 1912 the teeny tiny remanent Grand Pacific Glacier (now 210' thick and 2 miles wide) has retreated and advanced a mear 5 - 8 Miles!  If you look at the map, you will understand that Climate Changes always, there is no denying that. Hopefully this will give you a perspective that you don't get my listening to hypocritAl Gore, who has made a ton of money and creates more CO2 than you or I</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.009850</td>\n",
       "      <td>3.698180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797659</th>\n",
       "      <td>5096861</td>\n",
       "      <td>I'll bet that would be just tickety boo.</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.018650</td>\n",
       "      <td>3.585599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613111</th>\n",
       "      <td>992602</td>\n",
       "      <td>For the Trump administration and Trump himself, this was one of those boxes that had to be checked off. They are certainly aware of all the media reports from Canada, and knew they had to get this out of the way. Trump gave the appearance of a man who would rather have been back golfing in Florida. Watching and listening to him read his lines, was like watching paint dry. Success for Trudeau, was not having Trump go ballistic.</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.032791</td>\n",
       "      <td>3.417605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1412350</th>\n",
       "      <td>5845082</td>\n",
       "      <td>Aint he a stinka !?!\\n;-)</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.010581</td>\n",
       "      <td>3.187266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995133</th>\n",
       "      <td>5334657</td>\n",
       "      <td>No, dumdum-you dont get it. The business does not get to decide who he serves and who he does not. If he makes cakes for one, he must make them for ALL</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.042217</td>\n",
       "      <td>3.164943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166492</th>\n",
       "      <td>445572</td>\n",
       "      <td>Oh looky...here comes that rolling doughnut....time for you to take the flying leap...</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.026817</td>\n",
       "      <td>3.020120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941772</th>\n",
       "      <td>5270821</td>\n",
       "      <td>Comment 254\\n\\nDamn.  Are we stuck with this font?  Never mind.\\n\\nElizabeth Renzetti's article is a very good one.  It argues for allowing opinion, even on a hot topic.   (Especially on a hot topic, I'd say.)  \"Cultural appropriation: Why can't we debate it?\" she asks.  Well, the 253 comments before this one have been doing exactly that, so I guess that's her question answered.  But is anybody in this thread going to lose their job because of the views expressed here?  Not if their name is Retrofit, apparently.  So, why are people losing their jobs over this?  Because a smallish group of angry people disagree with their opinion?  Were Niedzvieki, Kay and Ladurantaye guilty of hate speech?  Is that why they lost their jobs?  No?  Then why did they lose their jobs over being part of a debate?  I support Renzetti's take on this.\\n\\nPart Two: The Thorny Question\\n\\nWhat do you think of Shakespeare's Richard III,  Orwell's 1984, and Twain's Huckleberry Finn?  Those books took some imagination, eh?</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.013560</td>\n",
       "      <td>3.014543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1344323</th>\n",
       "      <td>5758488</td>\n",
       "      <td>F\\nU\\nC\\nK\\nY\\nO\\nU\\nC\\nI\\nV\\nI\\nL\\nC\\nO\\nM\\nM\\nE\\nN\\nT\\nS</td>\n",
       "      <td>0.936916</td>\n",
       "      <td>0.041466</td>\n",
       "      <td>2.984760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1343898</th>\n",
       "      <td>5757957</td>\n",
       "      <td>conservative?\\nno\\nlunatic</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.007767</td>\n",
       "      <td>2.917850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1570066</th>\n",
       "      <td>6042937</td>\n",
       "      <td>Wow.  Unions...so scrwd</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.008439</td>\n",
       "      <td>2.868295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1651148</th>\n",
       "      <td>6145915</td>\n",
       "      <td>Hey TDS sufferers, MAGA and he is!</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.057120</td>\n",
       "      <td>2.862593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1227651</th>\n",
       "      <td>5615099</td>\n",
       "      <td>Fuktards just don't get it!</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.008743</td>\n",
       "      <td>2.847233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1500653</th>\n",
       "      <td>5957020</td>\n",
       "      <td>Hey \\nA\\nS\\nS\\nH\\nO\\nL\\nE\\nK\\nI\\nL\\nL\\nY\\nO\\nU\\nR\\nS\\nE\\nL\\nF</td>\n",
       "      <td>0.587500</td>\n",
       "      <td>0.008225</td>\n",
       "      <td>2.823751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389623</th>\n",
       "      <td>719603</td>\n",
       "      <td>Parity has worked out so well.  Monsef the Iranian Spy and Freeland the Weeper</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.036444</td>\n",
       "      <td>2.766170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67521</th>\n",
       "      <td>324813</td>\n",
       "      <td>With that surname, it's hard to take you seriously.</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.010137</td>\n",
       "      <td>2.759030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210886</th>\n",
       "      <td>500130</td>\n",
       "      <td>OH\\nMY\\nGORSH\\ntrump\\nIS\\nA\\nHORROR\\nSTORY\\n!!!!!</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.032129</td>\n",
       "      <td>2.756919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399684</th>\n",
       "      <td>731845</td>\n",
       "      <td>Soooo, can i step on your head if i apologize the next day. Lets give it a whirl</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.063694</td>\n",
       "      <td>2.753673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1089441</th>\n",
       "      <td>5448068</td>\n",
       "      <td>10-1 odds, this will be used against\\nCanadians who won't vote that useless\\nselfie boy.</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.038684</td>\n",
       "      <td>2.716853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1631604</th>\n",
       "      <td>6120568</td>\n",
       "      <td>Let them strike. There’s not a taxpayer in the county that’s going miss them.  Notice I said “taxpayer”</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.038842</td>\n",
       "      <td>2.713472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295319</th>\n",
       "      <td>603780</td>\n",
       "      <td>$20,000.00 = only $2,000.00 in real money\\nPATHETIC \\nWHO WAS THE JUDGE?</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>2.693175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774484</th>\n",
       "      <td>5067835</td>\n",
       "      <td>Snap! Only here it's the blasted Tories (Trump fans) who are relentlessly whittling National Health Service funding. \\n\\nCome the revolution...😎</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.069190</td>\n",
       "      <td>2.670897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743512</th>\n",
       "      <td>5031087</td>\n",
       "      <td>KROOKWELL the part-time mayor: \"Please...please won't you put some \"skin in the game\" and invest some money on the downtown, most expensive, most time consuming, most potentially litigated part of my vanity project??\"\\n\\nPrivate business reps: \"FUUUUUUUUUUUUUCK NO!!!! We ain't touching this abortion with a 100' pole!!!\"</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.069959</td>\n",
       "      <td>2.659848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1434191</th>\n",
       "      <td>5872351</td>\n",
       "      <td>Sounds to me like the author has a refuse worker in her family.</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.041664</td>\n",
       "      <td>2.655520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234777</th>\n",
       "      <td>5623734</td>\n",
       "      <td>Give me your address and I'll come over and touch you.</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.022773</td>\n",
       "      <td>2.654450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id    ...      logloss\n",
       "1774794  6296556    ...     4.881168\n",
       "1571265  6044462    ...     4.686455\n",
       "1552125  6021195    ...     3.981387\n",
       "107748   373929     ...     3.808011\n",
       "687700   1082705    ...     3.741680\n",
       "1179407  5557347    ...     3.734343\n",
       "1496912  5952533    ...     3.698180\n",
       "797659   5096861    ...     3.585599\n",
       "613111   992602     ...     3.417605\n",
       "1412350  5845082    ...     3.187266\n",
       "995133   5334657    ...     3.164943\n",
       "166492   445572     ...     3.020120\n",
       "941772   5270821    ...     3.014543\n",
       "1344323  5758488    ...     2.984760\n",
       "1343898  5757957    ...     2.917850\n",
       "1570066  6042937    ...     2.868295\n",
       "1651148  6145915    ...     2.862593\n",
       "1227651  5615099    ...     2.847233\n",
       "1500653  5957020    ...     2.823751\n",
       "389623   719603     ...     2.766170\n",
       "67521    324813     ...     2.759030\n",
       "210886   500130     ...     2.756919\n",
       "399684   731845     ...     2.753673\n",
       "1089441  5448068    ...     2.716853\n",
       "1631604  6120568    ...     2.713472\n",
       "295319   603780     ...     2.693175\n",
       "774484   5067835    ...     2.670897\n",
       "743512   5031087    ...     2.659848\n",
       "1434191  5872351    ...     2.655520\n",
       "1234777  5623734    ...     2.654450\n",
       "\n",
       "[30 rows x 5 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cv = StratifiedKFold(n_splits=n_splits, random_state=seed)\n",
    "for fold, (train_index, valid_index) in enumerate(cv.split(range(len(train)), np.where(train[target]>0.5, 1, 0))):\n",
    "    if fold==n_fold:\n",
    "        valid = train.loc[valid_index]\n",
    "        valid['pred'] = np.load(f'pred_valid_fold_{fold}.npy')[:, 0]\n",
    "        valid['logloss'] = log_loss(valid[target].values, valid['pred'].values)\n",
    "        break\n",
    "\n",
    "valid.sort_values('logloss', ascending=False).loc[:, ['id', 'comment_text', 'target', 'pred', 'logloss']].head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submission(y_pred):\n",
    "    sub = pd.read_csv('../input/jigsaw-unintended-bias-in-toxicity-classification/sample_submission.csv')\n",
    "    sub['prediction'] = y_pred[:, 0]\n",
    "    sub.to_csv('submission.csv', index=False)\n",
    "    return sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = prepare_data_loader(X_test, test_lengths, shuffle=False)\n",
    "\n",
    "pred_tests = []\n",
    "weights = sorted(glob.glob('weight_best_fold_*.pth'))\n",
    "for fold, path in enumerate(weights):\n",
    "    model = EmbLSTM(embedding_matrix, max_features).cuda()\n",
    "    state = torch.load(path)\n",
    "    model.load_state_dict(state['state_dict'])\n",
    "    \n",
    "    pred_test = predict_model(model, test_loader)\n",
    "    np.save(f'pred_test_fold_{fold}.npy', pred_test)\n",
    "    pred_tests.append(pred_test)\n",
    "    \n",
    "    del model; gc.collect(); torch.cuda.empty_cache()\n",
    "    \n",
    "pred_tests = np.mean(pred_tests, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7000000</td>\n",
       "      <td>0.036963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7000001</td>\n",
       "      <td>0.006404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7000002</td>\n",
       "      <td>0.082652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7000003</td>\n",
       "      <td>0.042890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7000004</td>\n",
       "      <td>0.799552</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  prediction\n",
       "0  7000000  0.036963  \n",
       "1  7000001  0.006404  \n",
       "2  7000002  0.082652  \n",
       "3  7000003  0.042890  \n",
       "4  7000004  0.799552  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = submission(pred_tests)\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()\n",
    "plt.hist(pred_tests[:, 0])\n",
    "plt.title('test histogram')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
