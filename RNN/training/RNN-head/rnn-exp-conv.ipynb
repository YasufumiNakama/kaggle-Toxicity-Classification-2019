{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base from https://www.kaggle.com/yasufuminakama/rnn-fold-models-no-gru/log?scriptVersionId=15790117\n",
    "# fold1:CV0.937474\n",
    "# drop_rate = 0.4\n",
    "# warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/opt/conda/lib/python3.6/site-packages/tqdm/autonotebook/__init__.py:14: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  \" (e.g. in jupyter console)\", TqdmExperimentalWarning)\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import gc\n",
    "import glob\n",
    "from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n",
    "import multiprocessing\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "\n",
    "from fastprogress import master_bar, progress_bar\n",
    "from keras.preprocessing import text, sequence\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize.treebank import TreebankWordTokenizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import shap\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tqdm._tqdm_notebook import tqdm_notebook as tqdm\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.utils.data import Dataset, DataLoader, Subset, TensorDataset\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set(style='ticks')\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/ildoonet/pytorch-gradual-warmup-lr/blob/master/warmup_scheduler/scheduler.py\n",
    "\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "\n",
    "class GradualWarmupScheduler(_LRScheduler):\n",
    "    \"\"\" Gradually warm-up(increasing) learning rate in optimizer.\n",
    "    Proposed in 'Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour'.\n",
    "    Args:\n",
    "        optimizer (Optimizer): Wrapped optimizer.\n",
    "        multiplier: target learning rate = base lr * multiplier\n",
    "        total_epoch: target learning rate is reached at total_epoch, gradually\n",
    "        after_scheduler: after target_epoch, use this scheduler(eg. ReduceLROnPlateau)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, optimizer, multiplier, total_epoch, after_scheduler=None):\n",
    "        self.multiplier = multiplier\n",
    "        if self.multiplier <= 1.:\n",
    "            raise ValueError('multiplier should be greater than 1.')\n",
    "        self.total_epoch = total_epoch\n",
    "        self.after_scheduler = after_scheduler\n",
    "        self.finished = False\n",
    "        super().__init__(optimizer)\n",
    "\n",
    "    def get_lr(self):\n",
    "        if self.last_epoch > self.total_epoch:\n",
    "            if self.after_scheduler:\n",
    "                if not self.finished:\n",
    "                    self.after_scheduler.base_lrs = [base_lr * self.multiplier for base_lr in self.base_lrs]\n",
    "                    self.finished = True\n",
    "                return self.after_scheduler.get_lr()\n",
    "            return [base_lr * self.multiplier for base_lr in self.base_lrs]\n",
    "\n",
    "        return [base_lr * ((self.multiplier - 1.) * self.last_epoch / self.total_epoch + 1.) for base_lr in self.base_lrs]\n",
    "\n",
    "    def step_ReduceLROnPlateau(self, metrics, epoch=None):\n",
    "        if epoch is None:\n",
    "            epoch = self.last_epoch + 1\n",
    "        self.last_epoch = epoch if epoch != 0 else 1  # ReduceLROnPlateau is called at the end of epoch, whereas others are called at beginning\n",
    "        if self.last_epoch <= self.total_epoch:\n",
    "            warmup_lr = [base_lr * ((self.multiplier - 1.) * self.last_epoch / self.total_epoch + 1.) for base_lr in self.base_lrs]\n",
    "            for param_group, lr in zip(self.optimizer.param_groups, warmup_lr):\n",
    "                param_group['lr'] = lr\n",
    "        else:\n",
    "            if epoch is None:\n",
    "                self.after_scheduler.step(metrics, None)\n",
    "            else:\n",
    "                self.after_scheduler.step(metrics, epoch - self.total_epoch)\n",
    "\n",
    "    def step(self, epoch=None, metrics=None):\n",
    "        if type(self.after_scheduler) != ReduceLROnPlateau:\n",
    "            if self.finished and self.after_scheduler:\n",
    "                if epoch is None:\n",
    "                    self.after_scheduler.step(None)\n",
    "                else:\n",
    "                    self.after_scheduler.step(epoch - self.total_epoch)\n",
    "            else:\n",
    "                return super(GradualWarmupScheduler, self).step(epoch)\n",
    "        else:\n",
    "            self.step_ReduceLROnPlateau(metrics, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "def get_logger():\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    # handler1\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(asctime)s %(levelname)8s %(message)s\"))\n",
    "    # handler2\n",
    "    handler2 = FileHandler(filename=datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")+\".log\")\n",
    "    handler2.setFormatter(Formatter(\"%(asctime)s %(levelname)8s %(message)s\"))\n",
    "    # addHandler\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "def seed_everything(seed=123):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def log_loss(y_true, y_pred, epsilon=1e-12):\n",
    "    y_pred = np.clip(y_pred, epsilon, 1-epsilon)\n",
    "    return -(np.log(y_pred) * y_true + np.log(1 - y_pred) * (1 - y_true))\n",
    "\n",
    "class JigsawEvaluator:\n",
    "    def __init__(self, y_true, y_identity, power=-5, overall_model_weight=0.25):\n",
    "        self.y = (y_true >= 0.5).astype(int)\n",
    "        self.y_i = (y_identity >= 0.5).astype(int)\n",
    "        self.n_subgroups = self.y_i.shape[1]\n",
    "        self.power = power\n",
    "        self.overall_model_weight = overall_model_weight\n",
    "\n",
    "    @staticmethod\n",
    "    def _compute_auc(y_true, y_pred):\n",
    "        try:\n",
    "            return roc_auc_score(y_true, y_pred)\n",
    "        except ValueError:\n",
    "            return np.nan\n",
    "\n",
    "    def _compute_subgroup_auc(self, i, y_pred):\n",
    "        mask = self.y_i[:, i] == 1\n",
    "        return self._compute_auc(self.y[mask], y_pred[mask])\n",
    "\n",
    "    def _compute_bpsn_auc(self, i, y_pred):\n",
    "        mask = self.y_i[:, i] + self.y == 1\n",
    "        return self._compute_auc(self.y[mask], y_pred[mask])\n",
    "\n",
    "    def _compute_bnsp_auc(self, i, y_pred):\n",
    "        mask = self.y_i[:, i] + self.y != 1\n",
    "        return self._compute_auc(self.y[mask], y_pred[mask])\n",
    "\n",
    "    def compute_bias_metrics_for_model(self, y_pred):\n",
    "        records = np.zeros((3, self.n_subgroups))\n",
    "        for i in range(self.n_subgroups):\n",
    "            records[0, i] = self._compute_subgroup_auc(i, y_pred)\n",
    "            records[1, i] = self._compute_bpsn_auc(i, y_pred)\n",
    "            records[2, i] = self._compute_bnsp_auc(i, y_pred)\n",
    "        return records\n",
    "\n",
    "    def _calculate_overall_auc(self, y_pred):\n",
    "        return roc_auc_score(self.y, y_pred)\n",
    "\n",
    "    def _power_mean(self, array):\n",
    "        total = sum(np.power(array, self.power))\n",
    "        return np.power(total / len(array), 1 / self.power)\n",
    "\n",
    "    def get_final_metric(self, y_pred):\n",
    "        bias_metrics = self.compute_bias_metrics_for_model(y_pred)\n",
    "        bias_score = np.average([\n",
    "            self._power_mean(bias_metrics[0]),\n",
    "            self._power_mean(bias_metrics[1]),\n",
    "            self._power_mean(bias_metrics[2])\n",
    "        ])\n",
    "        overall_score = self.overall_model_weight * self._calculate_overall_auc(y_pred)\n",
    "        bias_score = (1 - self.overall_model_weight) * bias_score\n",
    "        return overall_score + bias_score, bias_metrics[0], bias_metrics[1], bias_metrics[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logger\n",
    "logger = get_logger()\n",
    "\n",
    "# parameters\n",
    "n_workers = 4\n",
    "n_splits = 5\n",
    "seed = 777\n",
    "seed_everything(seed)\n",
    "\n",
    "maxlen = 300\n",
    "max_features = 410047\n",
    "\n",
    "batch_size = 512\n",
    "lr = 0.001\n",
    "epochs = 10\n",
    "n_fold = 1\n",
    "drop_rate = 0.4 # default=0.3\n",
    "\n",
    "# path\n",
    "CRAWL_EMBEDDING_PATH = '../input/pickled-crawl300d2m-for-kernel-competitions/crawl-300d-2M.pkl'\n",
    "GLOVE_EMBEDDING_PATH = '../input/pickled-glove840b300d-for-10sec-loading/glove.840B.300d.pkl'\n",
    "# GOOGLE_EMBEDDING_PATH = '../input/quoratextemb/embeddings/GoogleNews-vectors-negative300/GoogleNews-vectors-negative300.bin'\n",
    "# WIKI_EMBEDDING_PATH = '../input/quoratextemb/embeddings/wiki-news-300d-1M/wiki-news-300d-1M.vec'\n",
    "\n",
    "# constants\n",
    "target = 'target'\n",
    "aux_target = ['severe_toxicity', 'obscene', 'identity_attack', 'insult', 'threat']\n",
    "identity_columns = [\n",
    "    'male', 'female', 'homosexual_gay_or_lesbian', 'christian', 'jewish',\n",
    "    'muslim', 'black', 'white', 'psychiatric_or_mental_illness'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (1804874, 45)\n",
      "test shape: (97320, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>severe_toxicity</th>\n",
       "      <th>obscene</th>\n",
       "      <th>identity_attack</th>\n",
       "      <th>insult</th>\n",
       "      <th>threat</th>\n",
       "      <th>asian</th>\n",
       "      <th>atheist</th>\n",
       "      <th>bisexual</th>\n",
       "      <th>black</th>\n",
       "      <th>buddhist</th>\n",
       "      <th>christian</th>\n",
       "      <th>female</th>\n",
       "      <th>heterosexual</th>\n",
       "      <th>hindu</th>\n",
       "      <th>homosexual_gay_or_lesbian</th>\n",
       "      <th>intellectual_or_learning_disability</th>\n",
       "      <th>jewish</th>\n",
       "      <th>latino</th>\n",
       "      <th>male</th>\n",
       "      <th>muslim</th>\n",
       "      <th>other_disability</th>\n",
       "      <th>other_gender</th>\n",
       "      <th>other_race_or_ethnicity</th>\n",
       "      <th>other_religion</th>\n",
       "      <th>other_sexual_orientation</th>\n",
       "      <th>physical_disability</th>\n",
       "      <th>psychiatric_or_mental_illness</th>\n",
       "      <th>transgender</th>\n",
       "      <th>white</th>\n",
       "      <th>created_date</th>\n",
       "      <th>publication_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>funny</th>\n",
       "      <th>wow</th>\n",
       "      <th>sad</th>\n",
       "      <th>likes</th>\n",
       "      <th>disagree</th>\n",
       "      <th>sexual_explicit</th>\n",
       "      <th>identity_annotator_count</th>\n",
       "      <th>toxicity_annotator_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59848</td>\n",
       "      <td>0.0</td>\n",
       "      <td>This is so cool. It's like, 'would you want yo...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-09-29 10:50:41.987077+00</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2006</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59849</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Thank you!! This would make my life a lot less...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-09-29 10:50:42.870083+00</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2006</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59852</td>\n",
       "      <td>0.0</td>\n",
       "      <td>This is such an urgent design problem; kudos t...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-09-29 10:50:45.222647+00</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2006</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id            ...             toxicity_annotator_count\n",
       "0  59848            ...                                    4\n",
       "1  59849            ...                                    4\n",
       "2  59852            ...                                    4\n",
       "\n",
       "[3 rows x 45 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('../input/jigsaw-unintended-bias-in-toxicity-classification/train.csv')\n",
    "test = pd.read_csv('../input/jigsaw-unintended-bias-in-toxicity-classification/test.csv')\n",
    "print(f'train shape: {train.shape}')\n",
    "print(f'test shape: {test.shape}')\n",
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7000000</td>\n",
       "      <td>Jeff Sessions is another one of Trump's Orwell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7000001</td>\n",
       "      <td>I actually inspected the infrastructure on Gra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7000002</td>\n",
       "      <td>No it won't . That's just wishful thinking on ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                       comment_text\n",
       "0  7000000  Jeff Sessions is another one of Trump's Orwell...\n",
       "1  7000001  I actually inspected the infrastructure on Gra...\n",
       "2  7000002  No it won't . That's just wishful thinking on ..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "y shape: (1804874, 8)\n"
     ]
    }
   ],
   "source": [
    "# Overall\n",
    "weights = np.ones((len(train),)) / 4\n",
    "\n",
    "# Subgroup\n",
    "weights += (train[identity_columns].fillna(0).values>=0.5).sum(axis=1).astype(bool).astype(np.int) / 4\n",
    "\n",
    "# Background Positive, Subgroup Negative\n",
    "weights += (((train[target].values>=0.5).astype(bool).astype(np.int) +\n",
    "   (1-(train[identity_columns].fillna(0).values>=0.5).sum(axis=1).astype(bool).astype(np.int)) ) > 1).astype(bool).astype(np.int) / 4\n",
    "\n",
    "# Background Negative, Subgroup Positive\n",
    "weights += (((train[target].values<0.5).astype(bool).astype(np.int) +\n",
    "   (train[identity_columns].fillna(0).values>=0.5).sum(axis=1).astype(bool).astype(np.int) ) > 1).astype(bool).astype(np.int) / 4\n",
    "\n",
    "#loss_weight = 1.0 / weights.mean()\n",
    "loss_weight = 0.5\n",
    "print(loss_weight)\n",
    "\n",
    "y_train = np.vstack([train[target], weights]).T\n",
    "# y_train = np.vstack([np.where(train[target]>=0.5, train[target], 0), weights]).T\n",
    "y_aux_train = train[[target]+aux_target]\n",
    "y_train = np.hstack([y_train, y_aux_train])\n",
    "print(f'y shape: {y_train.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_pickle('../input/toxicpreprocesseddata/X_train.pkl')\n",
    "X_test = pd.read_pickle('../input/toxicpreprocesseddata/X_test.pkl')\n",
    "embedding_matrix = pd.read_pickle('../input/toxicpreprocesseddata/embedding_matrix.pkl')\n",
    "tokenizer = pd.read_pickle('../input/toxicpreprocesseddata/tokenizer.pkl')\n",
    "train_lengths = pd.read_pickle('../input/toxicpreprocesseddata/train_lengths.pkl')\n",
    "test_lengths = pd.read_pickle('../input/toxicpreprocesseddata/test_lengths.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceBucketCollator():\n",
    "    def __init__(self, choose_length, sequence_index, length_index, label_index=None):\n",
    "        self.choose_length = choose_length\n",
    "        self.sequence_index = sequence_index\n",
    "        self.length_index = length_index\n",
    "        self.label_index = label_index\n",
    "        \n",
    "    def __call__(self, batch):\n",
    "        batch = [torch.stack(x) for x in list(zip(*batch))]\n",
    "        \n",
    "        sequences = batch[self.sequence_index]\n",
    "        lengths = batch[self.length_index]\n",
    "        \n",
    "        length = self.choose_length(lengths)\n",
    "        mask = torch.arange(start=maxlen, end=0, step=-1) < length\n",
    "        padded_sequences = sequences[:, mask]\n",
    "        \n",
    "        batch[self.sequence_index] = padded_sequences\n",
    "        \n",
    "        if self.label_index is not None:\n",
    "            return [x for i, x in enumerate(batch) if i != self.label_index], batch[self.label_index]\n",
    "    \n",
    "        return batch\n",
    "    \n",
    "def prepare_data_loader(X, lengths, y=None, shuffle=False):\n",
    "    if y is None:\n",
    "        dataset = TensorDataset(torch.from_numpy(X), \n",
    "                                torch.from_numpy(lengths))\n",
    "        collator = SequenceBucketCollator(lambda lenghts: lenghts.max(), \n",
    "                                          sequence_index=0, \n",
    "                                          length_index=1)\n",
    "    else:\n",
    "        dataset = TensorDataset(torch.from_numpy(X), \n",
    "                                torch.from_numpy(lengths), \n",
    "                                torch.tensor(y, dtype=torch.float32))\n",
    "        collator = SequenceBucketCollator(lambda lenghts: lenghts.max(), \n",
    "                                          sequence_index=0, \n",
    "                                          length_index=1, \n",
    "                                          label_index=2)\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, collate_fn=collator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(data, targets):\n",
    "    ''' Define custom loss function for weighted BCE on 'target' column '''\n",
    "    bce_loss_1 = nn.BCEWithLogitsLoss(weight=targets[:, 1:2])(data[:, :1], targets[:, :1])\n",
    "    bce_loss_2 = nn.BCEWithLogitsLoss()(data[:, 1:], targets[:, 2:])\n",
    "    return (bce_loss_1 * loss_weight) + bce_loss_2\n",
    "\n",
    "#def custom_loss(data, targets):\n",
    "#    ''' Define custom loss function for weighted BCE on 'target' column '''\n",
    "#    bce_loss_1 = nn.BCEWithLogitsLoss(weight=targets[:, 1:2])(data[:, :1], targets[:, :1])\n",
    "#    return bce_loss_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpatialDropout(nn.Dropout2d):\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(2)    # (N, T, 1, K)\n",
    "        x = x.permute(0, 3, 2, 1)  # (N, K, 1, T)\n",
    "        x = super(SpatialDropout, self).forward(x)  # (N, K, 1, T), some features are masked\n",
    "        x = x.permute(0, 3, 2, 1)  # (N, T, 1, K)\n",
    "        x = x.squeeze(2)  # (N, T, K)\n",
    "        return x\n",
    "    \n",
    "class EmbLSTM(nn.Module):\n",
    "    def __init__(self, embedding_matrix, max_features, num_aux_targets=6):\n",
    "        super().__init__()\n",
    "        embed_size = embedding_matrix.shape[1]\n",
    "        \n",
    "        self.embedding = nn.Embedding(max_features, embed_size)\n",
    "        self.embedding.weight = nn.Parameter(torch.tensor(embedding_matrix, dtype=torch.float32))\n",
    "        self.embedding.weight.requires_grad = False\n",
    "        self.embedding_dropout = SpatialDropout(drop_rate)\n",
    "        \n",
    "        self.lstm1 = nn.LSTM(embed_size, 128, num_layers=1, bidirectional=True, batch_first=True)\n",
    "        #self.lstm2 = nn.LSTM(128 * 2, 128, num_layers=1, bidirectional=True, batch_first=True)\n",
    "        self.lstm2 = nn.GRU(128 * 2, 128, bidirectional=True, batch_first=True)\n",
    "    \n",
    "        #self.linear1 = nn.Linear(768, 768)\n",
    "        #self.linear2 = nn.Linear(768, 768)\n",
    "        self.linear1 = nn.Sequential(\n",
    "            nn.BatchNorm1d(768),\n",
    "            nn.Linear(768, 768),\n",
    "            #nn.PReLU(),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.linear2 = nn.Sequential(\n",
    "            nn.BatchNorm1d(768),\n",
    "            nn.Linear(768, 768),\n",
    "            #nn.PReLU(),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        \n",
    "        self.linear_out = nn.Linear(768, 1)\n",
    "        self.linear_aux_out = nn.Linear(768, num_aux_targets)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h_embedding = self.embedding(x)\n",
    "        h_embedding = self.embedding_dropout(h_embedding)\n",
    "        \n",
    "        h_lstm1, _ = self.lstm1(h_embedding)\n",
    "        h_lstm2, hh_lstm2 = self.lstm2(h_lstm1)\n",
    "        \n",
    "        hh_lstm2 = hh_lstm2.view(-1, 128 * 2)\n",
    "        \n",
    "        # global average pooling\n",
    "        avg_pool = torch.mean(h_lstm2, 1)\n",
    "        # global max pooling\n",
    "        max_pool, _ = torch.max(h_lstm2, 1)\n",
    "        \n",
    "        h_conc = torch.cat((hh_lstm2, max_pool, avg_pool), 1)\n",
    "        h_conc_linear1  = F.relu(self.linear1(h_conc))\n",
    "        h_conc_linear2  = F.relu(self.linear2(h_conc))\n",
    "        \n",
    "        hidden = h_conc + h_conc_linear1 + h_conc_linear2\n",
    "        \n",
    "        result = self.linear_out(hidden)\n",
    "        aux_result = self.linear_aux_out(hidden)\n",
    "        \n",
    "        out = torch.cat([result, aux_result], 1)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(filepath, model, optimizer, epoch):\n",
    "    state = {\n",
    "        'epoch': epoch,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "    }\n",
    "    torch.save(state, filepath)\n",
    "\n",
    "def plot_losses(train_losses, valid_losses, fold=0):\n",
    "    plt.clf()\n",
    "    plt.plot(train_losses, label='train')\n",
    "    plt.plot(valid_losses, label='valid')\n",
    "    plt.legend()\n",
    "    plt.title(f'loss history of fold {fold}')\n",
    "    plt.savefig(f'loss_history_of_fold_{fold}.png')\n",
    "    plt.show()\n",
    "    \n",
    "def plot_histogram(y_true, y_pred, n_bins=50, fold=0):\n",
    "    bins = np.linspace(0, 1, n_bins)\n",
    "    plt.clf()\n",
    "    plt.hist(y_pred[:, 0], bins=bins, label='pred')\n",
    "    plt.hist(y_true[:, 0], bins=bins, label='true')\n",
    "    plt.legend()\n",
    "    plt.title(f'validation histogram of fold {fold}')\n",
    "    plt.savefig(f'validation_histogram_of_fold_{fold}.png')\n",
    "    plt.show()\n",
    "    \n",
    "def plot_aucs(aucs, auc_type, fold=0):\n",
    "    total = sum(np.power(aucs, -5))\n",
    "    score = np.power(total / len(aucs), 1 / -5)\n",
    "    \n",
    "    plt.clf()\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    ax = sns.barplot(identity_columns, aucs)\n",
    "    for p in ax.patches:\n",
    "        ax.annotate(f'{p.get_height():.4f}', (p.get_x()+p.get_width()/2, int(p.get_height()*0.95)),\n",
    "                    ha='center', va='center', fontsize=20, color='blue', xytext=(0, 20), \n",
    "                    textcoords='offset points')\n",
    "    plt.xticks(rotation=10)\n",
    "    plt.title(f'{auc_type} {score} barplot of fold {fold}')\n",
    "    plt.savefig(f'{auc_type}_{score}_barplot_of_fold_{fold}.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, X):\n",
    "    logits = model(X)\n",
    "    probabilities = torch.sigmoid(logits)\n",
    "    return logits, probabilities\n",
    "        \n",
    "def evaluate_single_epoch(model, dataloader, criterion, epoch, evaluator, return_pred=False):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        valid_preds = []\n",
    "        loss_list = []\n",
    "        for i, (X, y) in enumerate(dataloader):\n",
    "            X = X[0].cuda().long() # X[0]: text sequences, X[1]: lengths\n",
    "            y = y.cuda().float()\n",
    "            logits, probabilities = inference(model, X)\n",
    "            \n",
    "            loss = criterion(logits, y)\n",
    "            loss_list.append(loss.item())\n",
    "            valid_preds.append(probabilities.cpu().numpy())\n",
    "        valid_preds = np.concatenate(valid_preds)\n",
    "\n",
    "        log_dict = {}\n",
    "        score, subgroup_auc, bpsn_auc, bnsp_auc = evaluator.get_final_metric(valid_preds[:, 0])\n",
    "        log_dict['score'] = score\n",
    "        log_dict['subgroup_auc'] = subgroup_auc\n",
    "        log_dict['bpsn_auc'] = bpsn_auc\n",
    "        log_dict['bnsp_auc'] = bnsp_auc\n",
    "        log_dict['loss'] = np.mean(loss_list)\n",
    "        \n",
    "        if return_pred:\n",
    "            log_dict['pred'] = valid_preds\n",
    "            \n",
    "    return log_dict\n",
    "\n",
    "def train_single_epoch(model, dataloader, criterion, optimizer, epoch, parent_bar, scheduler=None):\n",
    "    model.train()\n",
    "    log_dict = {}\n",
    "    log_dict['loss'] = 0\n",
    "    for X, y in progress_bar(dataloader, parent=parent_bar):\n",
    "        X = X[0].cuda().long() # X[0]: text sequences, X[1]: lengths\n",
    "        y = y.cuda().float()\n",
    "        logits, probabilities = inference(model, X)\n",
    "        \n",
    "        loss = criterion(logits, y)\n",
    "        log_dict['loss'] += loss.item() / len(dataloader)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        log_dict['lr'] = optimizer.param_groups[0]['lr']\n",
    "        \n",
    "    if scheduler is not None:\n",
    "        scheduler.step()\n",
    "        \n",
    "    return log_dict\n",
    "\n",
    "def predict_model(model, dataloader):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_preds = []\n",
    "        for i, X in enumerate(dataloader):\n",
    "            X = X[0].cuda().long() # X[0]: text sequences, X[1]: lengths\n",
    "            logits, probabilities = inference(model, X)\n",
    "            test_preds.append(probabilities.cpu().numpy())\n",
    "    test_preds = np.concatenate(test_preds)\n",
    "    return test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "513"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kfold = train.copy()\n",
    "kfold['fold_id'] = 0\n",
    "\n",
    "cv = StratifiedKFold(n_splits=n_splits, random_state=seed, shuffle=True)\n",
    "for fold, (train_index, valid_index) in enumerate(cv.split(range(len(train)), np.where(train[target]>0.5, 1, 0))):\n",
    "    kfold.loc[valid_index, 'fold_id'] = fold\n",
    "kfold[['fold_id']].to_csv('fold01.csv', index=False)\n",
    "\n",
    "del kfold; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 80\n",
    "\n",
    "class EmbLSTMGRUCNN(nn.Module):\n",
    "    def __init__(self, embedding_matrix, max_features, num_aux_targets=6):\n",
    "        super().__init__()\n",
    "        embed_size = embedding_matrix.shape[1]\n",
    "        \n",
    "        self.embedding = nn.Embedding(max_features, embed_size)\n",
    "        self.embedding.weight = nn.Parameter(torch.tensor(embedding_matrix, dtype=torch.float32))\n",
    "        self.embedding.weight.requires_grad = False\n",
    "        self.embedding_dropout = SpatialDropout(drop_rate)\n",
    "        \n",
    "        self.lstm1 = nn.LSTM(embed_size, hidden_size, bidirectional=True, batch_first=True)\n",
    "        self.lstm2 = nn.GRU(hidden_size * 2, hidden_size, bidirectional=True, batch_first=True)\n",
    "        self.cnn = nn.Conv1d(hidden_size * 2, hidden_size, kernel_size=3, padding=0)\n",
    "    \n",
    "        self.linear1 = nn.Sequential(\n",
    "            nn.BatchNorm1d(hidden_size * 2),\n",
    "            nn.Linear(hidden_size * 2, hidden_size * 2),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.linear2 = nn.Sequential(\n",
    "            nn.BatchNorm1d(hidden_size * 2),\n",
    "            nn.Linear(hidden_size * 2, hidden_size * 2),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.linear_out = nn.Linear(hidden_size * 2, 1)\n",
    "        self.linear_aux_out = nn.Linear(hidden_size * 2, num_aux_targets)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #print(\"x\", x.size())\n",
    "        h_embedding = self.embedding(x)\n",
    "        #print(\"h_embedding\", h_embedding.size())\n",
    "        h_embedding = self.embedding_dropout(h_embedding)\n",
    "        #print(\"h_embedding\", h_embedding.size())\n",
    "        \n",
    "        h_lstm1, _ = self.lstm1(h_embedding)\n",
    "        #print(\"h_lstm1\", h_lstm1.size())\n",
    "        h_lstm2, _ = self.lstm2(h_lstm1)\n",
    "        #print(\"h_lstm2\", h_lstm2.size())\n",
    "        x = self.cnn(h_lstm2.permute(0, 2, 1))\n",
    "        #print(\"x\", x.size())\n",
    "        \n",
    "        # global average pooling\n",
    "        #avg_pool = torch.mean(x, 1)\n",
    "        avg_pool = torch.mean(x.permute(0, 2, 1), 1)\n",
    "        #print(\"avg_pool:\", avg_pool.size())\n",
    "        # global max pooling\n",
    "        #max_pool, _ = torch.max(x, 1)\n",
    "        max_pool, _ = torch.max(x.permute(0, 2, 1), 1)\n",
    "        #print(\"max_pool:\", max_pool.size())\n",
    "        \n",
    "        h_conc = torch.cat((max_pool, avg_pool), 1)\n",
    "        #print(\"h_conc:\", h_conc.size())\n",
    "        h_conc_linear1  = self.linear1(h_conc)\n",
    "        h_conc_linear2  = self.linear2(h_conc)\n",
    "        #print(\"h_conc_linear1:\", h_conc_linear1.size())\n",
    "        #print(\"h_conc_linear2:\", h_conc_linear2.size())\n",
    "        \n",
    "        hidden = h_conc + h_conc_linear1 + h_conc_linear2\n",
    "        #print(\"hidden:\", hidden.size())\n",
    "        \n",
    "        result = self.linear_out(hidden)\n",
    "        aux_result = self.linear_aux_out(hidden)\n",
    "        \n",
    "        out = torch.cat([result, aux_result], 1)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:33: RuntimeWarning: invalid value encountered in greater_equal\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1' class='' max='10', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      10.00% [1/10 07:15<1:05:17]\n",
       "    </div>\n",
       "    \n",
       "Epoch 1 - avg_train_loss: 0.1520  avg_val_loss: 0.1458  val_score: 0.926878<p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='612' class='' max='2821', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      21.69% [612/2821 01:26<05:10]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-22 18:59:34,579     INFO Epoch 1 - avg_train_loss: 0.1520 avg_val_loss: 0.1458  val_score: 0.926878\n"
     ]
    }
   ],
   "source": [
    "#cv = StratifiedKFold(n_splits=n_splits, random_state=seed)\n",
    "for fold, (train_index, valid_index) in enumerate(cv.split(range(len(train)), np.where(train[target]>0.5, 1, 0))):\n",
    "    if fold==n_fold:\n",
    "        \n",
    "        # data split\n",
    "        X_trn, X_val = X_train[train_index], X_train[valid_index]\n",
    "        y_trn, y_val = y_train[train_index], y_train[valid_index]\n",
    "        trn_lengths, val_lengths = train_lengths[train_index], train_lengths[valid_index]\n",
    "        y_val_target = train.loc[valid_index, target].values\n",
    "        y_val_identity = train.loc[valid_index, identity_columns].values\n",
    "    \n",
    "        train_loader = prepare_data_loader(X_trn, trn_lengths, y=y_trn, shuffle=True)\n",
    "        valid_loader = prepare_data_loader(X_val, val_lengths, y=y_val, shuffle=False)\n",
    "        evaluator = JigsawEvaluator(y_val_target, y_val_identity)\n",
    "    \n",
    "        # model\n",
    "        #model = EmbLSTM(embedding_matrix, max_features).cuda()\n",
    "        #model = ToxicLSTM(embedding_matrix, max_features).cuda()\n",
    "        model = EmbLSTMGRUCNN(embedding_matrix, max_features).cuda()\n",
    "        criterion = custom_loss\n",
    "        optimizer = torch.optim.Adam(params=model.parameters(), lr=lr, amsgrad=False)\n",
    "        scheduler_cosine = CosineAnnealingLR(optimizer, T_max=4, eta_min=1e-3)\n",
    "        scheduler = GradualWarmupScheduler(optimizer, multiplier=1.2, total_epoch=2, after_scheduler=scheduler_cosine)\n",
    "    #     scheduler = CosineAnnealingLR(optimizer, T_max=t_max, eta_min=eta_min)\n",
    "    #     scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lambda epoch: 0.6 ** epoch)\n",
    "    \n",
    "        # main loop\n",
    "        best_epoch = -1\n",
    "        best_score = 0.\n",
    "\n",
    "        train_losses, valid_losses = [], []\n",
    "\n",
    "        mb = master_bar(range(epochs))\n",
    "        for epoch in mb:\n",
    "            scheduler.step() # 2 epoch warmup, after that schedule as scheduler_cosine\n",
    "            #logger.info(f'Epoch {epoch+1} - optimizer: {optimizer.state_dict()[\"param_groups\"]} - scheduler: {scheduler.state_dict()}')\n",
    "            log_dict_train = train_single_epoch(model, train_loader, criterion, optimizer, epoch, mb) # loss, lr\n",
    "            log_dict_valid = evaluate_single_epoch(model, valid_loader, criterion, epoch, evaluator) # loss, score\n",
    "            train_losses.append(log_dict_train['loss'])\n",
    "            valid_losses.append(log_dict_valid['loss'])\n",
    "\n",
    "            if (epoch + 1) % 1 == 0:\n",
    "                mb.write(f'Epoch {epoch+1} - avg_train_loss: {log_dict_train[\"loss\"]:.4f}  avg_val_loss: {log_dict_valid[\"loss\"]:.4f}  val_score: {log_dict_valid[\"score\"]:.6f}')\n",
    "                logger.info(f'Epoch {epoch+1} - avg_train_loss: {log_dict_train[\"loss\"]:.4f} avg_val_loss: {log_dict_valid[\"loss\"]:.4f}  val_score: {log_dict_valid[\"score\"]:.6f}')\n",
    "\n",
    "            if log_dict_valid[\"score\"] > best_score:\n",
    "                best_epoch = epoch + 1\n",
    "                best_score = log_dict_valid[\"score\"]\n",
    "                save_checkpoint(f'weight_best_fold_{fold}.pth', model, optimizer, epoch)\n",
    "                if epoch - best_epoch > 3:\n",
    "                    break\n",
    "\n",
    "        # load best\n",
    "        state = torch.load(f'weight_best_fold_{fold}.pth')\n",
    "        model.load_state_dict(state['state_dict'])\n",
    "        optimizer.load_state_dict(state['optimizer'])\n",
    "\n",
    "        # save valid\n",
    "        log_dict = evaluate_single_epoch(model, valid_loader, criterion, 0, evaluator, return_pred=True)\n",
    "        pred_valid = log_dict['pred']\n",
    "        np.save(f'pred_valid_fold_{fold}.npy', pred_valid)\n",
    "\n",
    "        # evaluate\n",
    "        score, subgroup_auc, bpsn_auc, bnsp_auc = evaluator.get_final_metric(pred_valid[:, 0])\n",
    "        subgroup_auc = evaluator._power_mean(subgroup_auc)\n",
    "        bpsn_auc = evaluator._power_mean(bpsn_auc)\n",
    "        bnsp_auc = evaluator._power_mean(bnsp_auc)\n",
    "        overall_auc = evaluator._calculate_overall_auc(pred_valid[:, 0])\n",
    "        logger.info(f'metric: {score:.6f}, overall auc: {overall_auc:.6f}, subgroup_auc: {subgroup_auc:.6f}, bpsn_auc: {bpsn_auc:.6f}, bnsp_auc: {bnsp_auc:.6f}')\n",
    "        \n",
    "        # plot\n",
    "        plot_losses(train_losses, valid_losses, fold=fold)\n",
    "        plot_histogram(y_val, pred_valid, n_bins=50, fold=fold)\n",
    "        plot_aucs(log_dict['subgroup_auc'], 'subgroup_auc', fold=fold)\n",
    "        plot_aucs(log_dict['bpsn_auc'], 'bpsn_auc', fold=fold)\n",
    "        plot_aucs(log_dict['bnsp_auc'], 'bnsp_auc', fold=fold)\n",
    "    \n",
    "        del model; gc.collect(); torch.cuda.empty_cache()\n",
    "    \n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>target</th>\n",
       "      <th>pred</th>\n",
       "      <th>logloss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1764964</th>\n",
       "      <td>6284786</td>\n",
       "      <td>&gt;&gt;&gt; The link was clicked twice\\n\\nIdiots.</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.004428</td>\n",
       "      <td>5.113261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960637</th>\n",
       "      <td>5293418</td>\n",
       "      <td>yes, stupiditing</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.011120</td>\n",
       "      <td>4.050258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1179407</th>\n",
       "      <td>5557347</td>\n",
       "      <td>one ILH in top tier? Shows oia is scaid  ILH would play against itself every year.</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.009581</td>\n",
       "      <td>3.720279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1536867</th>\n",
       "      <td>6002824</td>\n",
       "      <td>fuckcorygardner.org</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.006283</td>\n",
       "      <td>3.550828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1613432</th>\n",
       "      <td>6097463</td>\n",
       "      <td>sit it out stupiddd</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.020064</td>\n",
       "      <td>3.519954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1751271</th>\n",
       "      <td>6268828</td>\n",
       "      <td>Well,I guess that's why they call the boy \"Spook Niggy Nigg\"</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.032184</td>\n",
       "      <td>3.436292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189740</th>\n",
       "      <td>473165</td>\n",
       "      <td>KISS\\n\\nKEEP   IT   SIMPLE   STUPID\\n\\nTalk now about a SuperGrid future, but work on offering our quickest quality export product to Japan now, which is LPG-propane and AK-GTL'\\n\\nSTUB2HUB &gt; Deadhorse to Fairbanks, ASAP with flexpipe only.\\n$500million CAPEX-risk.\\n\\nSiluria turns natural gas into gasoline for $1 per gallon\\nSiluria partners with oil industry giants to make fuels cheaply\\n\\nDo Not focus on selling LNG first in 2016, keep it on the backburner.\\nFocus on micro-GTL  and  micro-GTG  plants located in Fairbanks.\\nTrying to save TAPS in it's current configuration is packing sand down a rathole.\\n\\nhttp://siluria.com/</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.014545</td>\n",
       "      <td>3.387318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797659</th>\n",
       "      <td>5096861</td>\n",
       "      <td>I'll bet that would be just tickety boo.</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.025634</td>\n",
       "      <td>3.300050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1343898</th>\n",
       "      <td>5757957</td>\n",
       "      <td>conservative?\\nno\\nlunatic</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.005245</td>\n",
       "      <td>3.152355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762096</th>\n",
       "      <td>5052932</td>\n",
       "      <td>Sorry larned we dont have cash to keep blowing on so called art. Rather have things that payoff, like the wall to keep out the scumbums.</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.024282</td>\n",
       "      <td>3.102464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442596</th>\n",
       "      <td>785850</td>\n",
       "      <td>sanity finally in the usa after 8 years of stupdity</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.020869</td>\n",
       "      <td>3.099819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1227651</th>\n",
       "      <td>5615099</td>\n",
       "      <td>Fuktards just don't get it!</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.006375</td>\n",
       "      <td>3.035806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1187370</th>\n",
       "      <td>5567324</td>\n",
       "      <td>The buffoonest of all time.</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.027985</td>\n",
       "      <td>2.984793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1673702</th>\n",
       "      <td>6173720</td>\n",
       "      <td>Is there at way they could \"fire\" each other ?!\\nSimultaneously  .-)</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.051533</td>\n",
       "      <td>2.965526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1625504</th>\n",
       "      <td>6113076</td>\n",
       "      <td>What a  Dyck!</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.015762</td>\n",
       "      <td>2.909880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613111</th>\n",
       "      <td>992602</td>\n",
       "      <td>For the Trump administration and Trump himself, this was one of those boxes that had to be checked off. They are certainly aware of all the media reports from Canada, and knew they had to get this out of the way. Trump gave the appearance of a man who would rather have been back golfing in Florida. Watching and listening to him read his lines, was like watching paint dry. Success for Trudeau, was not having Trump go ballistic.</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.054967</td>\n",
       "      <td>2.901024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1516903</th>\n",
       "      <td>5977392</td>\n",
       "      <td>\"Then you can beat me up!\"\\nLogan, thanks for responding, but you misunderstand me-- you seem to want to spin this comics survey  as an adversarial issue but I have no interest in \"beating you up.\"  All I'm asking as that you show a little transparency,  publish the results of your survey now, which would be very interesting sociology  on the comic tastes of out community,  and you can save the writeup and decision making for October 1. If others want to attack you over your decisions then that's their business.\\n Really Logan, not everything  has to be framed as \"conflict\", we're better off when  we try to reach \"understanding.\"  Flexibility is not a  crime.</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.027042</td>\n",
       "      <td>2.893786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211708</th>\n",
       "      <td>501109</td>\n",
       "      <td>After I just got that last of my leaves raked up... Dang it!</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.017276</td>\n",
       "      <td>2.846139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1245691</th>\n",
       "      <td>5637001</td>\n",
       "      <td>Animals 😠</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.033331</td>\n",
       "      <td>2.840031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355487</th>\n",
       "      <td>678377</td>\n",
       "      <td>will poeple with crimanle back grounds get housing......the salem housing athority dose not rent to poeple with crimenle back grounds.....</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.019059</td>\n",
       "      <td>2.777936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415814</th>\n",
       "      <td>752064</td>\n",
       "      <td>In this case, anyway, I have bad news for you.\\n\\nURStupid</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.064497</td>\n",
       "      <td>2.741129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1797121</th>\n",
       "      <td>6323662</td>\n",
       "      <td>exedeus your statement is pure rubbish\\n\\nUkraine is neither our ally nor NATO's</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.015915</td>\n",
       "      <td>2.691371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336289</th>\n",
       "      <td>5748475</td>\n",
       "      <td>U \\nLike\\nSucking\\nBlack\\nC\\nO\\nC\\nK</td>\n",
       "      <td>0.965015</td>\n",
       "      <td>0.062959</td>\n",
       "      <td>2.670802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1380377</th>\n",
       "      <td>5804934</td>\n",
       "      <td>Not only irrelevant but inapt. Delete.</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.071732</td>\n",
       "      <td>2.634818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270804</th>\n",
       "      <td>574061</td>\n",
       "      <td>Yes, but once limbs, etc. are trimmed, they wind-up on the forest floor.</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.005376</td>\n",
       "      <td>2.615567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683976</th>\n",
       "      <td>1078310</td>\n",
       "      <td>So I have 2 down votes. Next time you don't feel like paying contract obligations see what happens.\\nAs for the curent mess - it is a sunk cost and our only option is to stop \"green energy\" ( solar &amp; wind ) and hook up to Quebec hydro, and/or go nuclear, ..... Either way we are s c r e w e d .......</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.039682</td>\n",
       "      <td>2.589581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1312112</th>\n",
       "      <td>5718746</td>\n",
       "      <td>In the future American children are going to think the Tuskegee airmen singlehandedly won WW2.  My god, ENOUGH VIRTUE SIGNALLING ALREADY...\\n\\nLibidiots ruin everything..  The Tuskegee airmen will be no different.  I'm sick of hearing about them.  For every one Saving Private Ryan we get 10 movies about the Tuskegee Airmen...</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.039958</td>\n",
       "      <td>2.584097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610019</th>\n",
       "      <td>988595</td>\n",
       "      <td>Not much news anywhere but for CBC, CTV &amp; the rest  of the widely read and  believed Canadian MSM.\\nAn average American would have difficulties finding Canada on the world map.</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.006741</td>\n",
       "      <td>2.503151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355998</th>\n",
       "      <td>679029</td>\n",
       "      <td>Shhhh check with the war room team lead for new talking points, these just make you look silly\\n\\nLIV on Cassandra... LIV on</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.016312</td>\n",
       "      <td>2.476099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1713813</th>\n",
       "      <td>6223099</td>\n",
       "      <td>Very, very whitefishy!</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.002289</td>\n",
       "      <td>2.433269</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id    ...      logloss\n",
       "1764964  6284786    ...     5.113261\n",
       "960637   5293418    ...     4.050258\n",
       "1179407  5557347    ...     3.720279\n",
       "1536867  6002824    ...     3.550828\n",
       "1613432  6097463    ...     3.519954\n",
       "1751271  6268828    ...     3.436292\n",
       "189740   473165     ...     3.387318\n",
       "797659   5096861    ...     3.300050\n",
       "1343898  5757957    ...     3.152355\n",
       "762096   5052932    ...     3.102464\n",
       "442596   785850     ...     3.099819\n",
       "1227651  5615099    ...     3.035806\n",
       "1187370  5567324    ...     2.984793\n",
       "1673702  6173720    ...     2.965526\n",
       "1625504  6113076    ...     2.909880\n",
       "613111   992602     ...     2.901024\n",
       "1516903  5977392    ...     2.893786\n",
       "211708   501109     ...     2.846139\n",
       "1245691  5637001    ...     2.840031\n",
       "355487   678377     ...     2.777936\n",
       "415814   752064     ...     2.741129\n",
       "1797121  6323662    ...     2.691371\n",
       "1336289  5748475    ...     2.670802\n",
       "1380377  5804934    ...     2.634818\n",
       "270804   574061     ...     2.615567\n",
       "683976   1078310    ...     2.589581\n",
       "1312112  5718746    ...     2.584097\n",
       "610019   988595     ...     2.503151\n",
       "355998   679029     ...     2.476099\n",
       "1713813  6223099    ...     2.433269\n",
       "\n",
       "[30 rows x 5 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cv = StratifiedKFold(n_splits=n_splits, random_state=seed)\n",
    "for fold, (train_index, valid_index) in enumerate(cv.split(range(len(train)), np.where(train[target]>0.5, 1, 0))):\n",
    "    if fold==n_fold:\n",
    "        valid = train.loc[valid_index]\n",
    "        valid['pred'] = np.load(f'pred_valid_fold_{fold}.npy')[:, 0]\n",
    "        valid['logloss'] = log_loss(valid[target].values, valid['pred'].values)\n",
    "        break\n",
    "\n",
    "valid.sort_values('logloss', ascending=False).loc[:, ['id', 'comment_text', 'target', 'pred', 'logloss']].head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submission(y_pred):\n",
    "    sub = pd.read_csv('../input/jigsaw-unintended-bias-in-toxicity-classification/sample_submission.csv')\n",
    "    sub['prediction'] = y_pred[:, 0]\n",
    "    sub.to_csv('submission.csv', index=False)\n",
    "    return sub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test_loader = prepare_data_loader(X_test, test_lengths, shuffle=False)\n",
    "\n",
    "pred_tests = []\n",
    "weights = sorted(glob.glob('weight_best_fold_*.pth'))\n",
    "for fold, path in enumerate(weights):\n",
    "    model = EmbLSTM(embedding_matrix, max_features).cuda()\n",
    "    state = torch.load(path)\n",
    "    model.load_state_dict(state['state_dict'])\n",
    "    \n",
    "    pred_test = predict_model(model, test_loader)\n",
    "    np.save(f'pred_test_fold_{fold}.npy', pred_test)\n",
    "    pred_tests.append(pred_test)\n",
    "    \n",
    "    del model; gc.collect(); torch.cuda.empty_cache()\n",
    "    \n",
    "pred_tests = np.mean(pred_tests, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sub = submission(pred_tests)\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.clf()\n",
    "plt.hist(pred_tests[:, 0])\n",
    "plt.title('test histogram')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
